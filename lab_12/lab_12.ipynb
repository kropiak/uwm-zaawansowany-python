{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d384b2-f096-4432-ac2e-384192913de4",
   "metadata": {},
   "source": [
    "# Lab 12. Przetwarzanie równoległe w Pythonie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6deda6-5bb3-4174-a4ae-f6a61eb2e64d",
   "metadata": {},
   "source": [
    "## 1. Pakiet `multiprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece1c07-8ba1-491b-a1e6-c6a4af64be78",
   "metadata": {},
   "source": [
    "Ten pakiet dostarcza API, które pozwala na uruchamianie kodu Python w oddzielnych procesach. Jak zostało wspomniane w poprzednim laboratorium, proces posiada swoją oddzielną pulę pamięci, własną blokadę GIL, i uruchamiany jest jako podprocess w ramach nowej instancji obiektu `multiprocessing.Process`, który korzysta z kolejnego wywołania interpretera Pythona.\n",
    "\n",
    "API `threading` oraz `multiprocessing` jest w wielu miejscach podobne, ale `multiprocessing` wprowadza dodatkowe elementy pozwalające na obsługę zadań w ramach programowania wieloprocesowego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f6f40-2969-4912-a585-26fa9aaf7d4f",
   "metadata": {},
   "source": [
    "_**Przykład 1**_\n",
    "\n",
    "Ten przykład pochodzi z dokumnetacji pakietu `multiprocessing`: https://docs.python.org/3/library/multiprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab51278-8618-4439-9d7f-b13e0a616db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main line\n",
      "module name: __main__\n",
      "parent process: 23908\n",
      "process id: 21596\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "def info(title):\n",
    "    print(title)\n",
    "    print('module name:', __name__)\n",
    "    print('parent process:', os.getppid())\n",
    "    print('process id:', os.getpid())\n",
    "\n",
    "def f(name):\n",
    "    info('function f')\n",
    "    print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    info('main line')\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948af2b3-0b9f-447b-bc55-53dd31872ccd",
   "metadata": {},
   "source": [
    "Po przeanalizowaniu kodu dojdziemy do wniosku, że w outpucie brakuje kilku linii (wypisywanych przez `print`), które powinny się tu pojawić. Uruchamianie kodu wykorzystującego kod wieloprocesowy odbywa się inaczej w przypadku systemów POISIX oraz Windows. Dodatkowo jeszcze dochodzą niuanse związane z uruchamianiem takiego kodu w środowisku Jupyter Notebook.\n",
    "\n",
    "O szczegółach można przeczytac między innymi w tym artykule: https://bobswinkels.com/posts/multiprocessing-python-windows-jupyter/\n",
    "\n",
    "Kod prezentowany tutaj winien być uruchamiany z pominięciem Jupyter Notebook. Dodatkowo wyjaśnienia wymaga pojawienie się tutaj linii `if __name__ == '__main__':`, której obecność jest związana z dobrymi praktykami programowania w samym Pythonie, ale tutaj powodem jest również natura programów wieloprocesowych w Pythonie. Zostało to opisane w dokumentacji modułu `multiprocessing` w sekcji `https://docs.python.org/3/library/multiprocessing.html#programming-guidelines` podpunkt `Safe importing of main module`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858e81a-033f-43a1-adbe-e86b32d7aa59",
   "metadata": {},
   "source": [
    "Po umieszczeniu kody w pliku i uruchomieniu wyjście będzie wyglądało tak:\n",
    "\n",
    "```console\n",
    "main line\n",
    "module name: __main__\n",
    "parent process: 16948\n",
    "process id: 33600    \n",
    "function f\n",
    "module name: __mp_main__\n",
    "parent process: 33600   \n",
    "process id: 11788       \n",
    "hello bob\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ba12f-d0fc-4da3-a8ba-483e6f00217f",
   "metadata": {},
   "source": [
    "Widać, że sama logika wywołania zadania w ramach nowego procesu nie różni się w tym przykładzie od tej zaprezentowanej w poprzednim laboratorium, a prezentującej wykorzystanie wątków w Pythonie.\n",
    "\n",
    "Poniżej zamieszczony zostanie przykład wykonania tej samej operacji z wykorzystaniem wątków oraz procesów dla porównania czasu wykonania, ale również przedstawienia podobieństw implementacji dla trywialnych zadań."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485921e4-d8d7-434d-b728-fe5f19ce2097",
   "metadata": {},
   "source": [
    "_**Przykład 2**_\n",
    "\n",
    "> UWAGA! Dla spójności wyników kod uruchamiamy poprzez wywołanie pliku z kodem w interpreterze Pythona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff462d-97ec-4d7b-b651-9d63582566d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik: fibo_threads.py\n",
    "\n",
    "import os\n",
    "import threading\n",
    "from time import perf_counter\n",
    "\n",
    "def fib(n):\n",
    "    return n if n < 2 else fib(n - 2) + fib(n - 1)\n",
    "\n",
    "threads = []\n",
    "print('Uruchamianie wątków...')\n",
    "t0 = perf_counter()\n",
    "\n",
    "for _ in range(os.cpu_count()):\n",
    "    threads.append(threading.Thread(target=fib, args=(25,)))\n",
    "\n",
    "for t in threads:\n",
    "    t.start()   \n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f'Czas wykonania: {perf_counter() - t0}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec7b92-9a23-4975-b933-0929ea411691",
   "metadata": {},
   "source": [
    "Pojedyncze uruchomienie tego kodu nie da nam faktycznego czasu wykonania tego kodu, więc operację najlepiej powtórzyć więcej razy i czas uśrednić. Przprowadzone testy dały średni czas na poziomie ~ 0.16 sekundy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5285338-788c-4a9b-a7f4-7392a7f5383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik fibo_processes.py\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from time import perf_counter\n",
    "\n",
    "def fib(n):\n",
    "    return n if n < 2 else fib(n - 2) + fib(n - 1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    processes = []\n",
    "    print('Uruchamianie procesów...')\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    for _ in range(os.cpu_count()):\n",
    "        processes.append(mp.Process(target=fib, args=(25,)))\n",
    "\n",
    "    for t in processes:\n",
    "        t.start()   \n",
    "\n",
    "    for t in processes:\n",
    "        t.join()\n",
    "\n",
    "    print(f'Czas wykonania: {perf_counter() - t0}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d21e7-3f9e-407a-a9e6-19ceabfd946f",
   "metadata": {},
   "source": [
    "Średni czas wykonania był na poziomie 0.372 sekundy, a więc wolniej. To może dziwić, biorąc pod uwagę, że wątki wykonują się `współbieżnie` współdzieląc między sobą czas procesora, a procesy uruchamiane są `równolegle` na oddzielnych rdzeniach. Tutaj wyjaśnieniem może być dużo większy narzut (dodatkowe operacje) przy inicjalizacji zasobów i obsłudze procesów względem wątków. Jeżeli zwiększymy wartość parametru `n` dla funkcji `fibo()` to zaobserwujemy, że czas wykonania zaczyna się zmieniać na korzyść rozwiązania opartego o procesy.\n",
    "\n",
    "Dla wywołania `fibo(40)` czas wykonania dla procesów wyniósł ~ 38 sekund, a dla wątków około 207 sekund. Widać zatem, że dla zadań z czasochłonnych ten przyrost wydajności będzie po stronie procesów. W trakcie wykonania kodu z przykładów zwróć uwagę na obciążenie procesora w systemowym monitorze zasobów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d660dd8-dd2c-4c0a-a9ff-5d1935fd551d",
   "metadata": {},
   "source": [
    "**Zadanie 1**\n",
    "\n",
    "Napisz rozwiązanie, które wykona test czasu wykonania dwóch powyższych przykładów ze wskazaną ilością powtórzeń (ale weź pod uwagę, że to są dość czasochłonne zadania dobierając tę liczbę) oraz dla wskazanego `n` dla funkcji `fibo()`. Wyniki zapisuj do pliku csv w formacie:\n",
    "numer_testu, fibo_n, sredni_czas.\n",
    "\n",
    "Następnie przygotuj wykres w Jupyter Notebooku, na którym porównaj czasy wykonania dla tych dwóch rozwiązań. Każde rozwziązanie to oddzielna seria danych na wykresie  - niech to będzie wykres liniowy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcde343-306a-4de4-a5be-7d397d0ce25c",
   "metadata": {},
   "source": [
    "**Pula procesów oraz komunikacja między procesami**\n",
    "\n",
    "Jak zostało już wspomniane na poprzednich zajęciach, proces komunikacji między procesami nie jest taki prosty jak w przypadku wątków. Wymaga to serializacji i desieralizacji danych odpowiednio przed ich przesłaniem i po ich odebraniu. To stanowi dość duży koszt w całym procesie wymiany danych. W tej części laboratorium przedstawione zostaną przykłady kolejek (ang. `queues`) oraz potoków (ang. `pipes`), które udostępnia moduł `multiprocessing`. Zaczniemy jednak od przedstawienia przykładu wykorzystującego pulę procesów.\n",
    "\n",
    "> Dokumentacja klasy Pool: https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool  \n",
    "> Dokumentacja Queue oraz Pipe:  \n",
    "> * https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes\n",
    "> * https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue\n",
    "> * https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e160b7b-7151-4461-8a43-d484afc82beb",
   "metadata": {},
   "source": [
    "_**Przykład 3**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0f911-1c08-4169-a216-27f715682fec",
   "metadata": {},
   "source": [
    "W poniższym przykładzie tworzona jest pula procesów, do której przekazywane są kolejne zadania poprzez metodę `map`, która jest zrównolegloną wersją wbudowanej funkcji map. Ta metoda rozdziela obiekt iterowalny na fragmenty i przekazuje kolejnym procesom do wykonania jako argument funkcji uruchamianej w ramach procesu. Podział obiektu iterowanego na fragmenty (ang. chunk's) automatycznie pobiera po jednym elemencie, ale można określić wielkość tego fragmentu (właściwa wielkość będzie przybliżona do podanej) poprzez parametr `chunksize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03dd39a-229f-4200-bd73-7df1abca192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik: process_pool_1.py\n",
    "import multiprocessing as mp\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "def fib(n):\n",
    "    return n if n < 2 else fib(n - 2) + fib(n - 1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print('Uruchamianie procesów...')\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # tworzymy pulę 8 procesów\n",
    "    with mp.Pool(processes=8) as pool:\n",
    "        # wyniki są zbierane do listy\n",
    "        results = pool.map(fib, range(40))\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"fib({i}) = {result}\")\n",
    "\n",
    "    print(f'Czas wykonania: {perf_counter() - t0}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcd0de-a67a-4da0-a06f-dc3e03488be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik: process_pool_2.py\n",
    "import multiprocessing as mp\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "def sum_nums(*nums):\n",
    "    return sum(nums)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print('Uruchamianie procesów...')\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # tworzymy pulę 8 procesów\n",
    "    with mp.Pool(processes=8) as pool:\n",
    "        # wyniki są zbierane do listy\n",
    "        results = pool.map(sum_nums, range(40), chunksize=4)\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"sum_nums({i}) = {result}\")\n",
    "\n",
    "    print(f'Czas wykonania: {perf_counter() - t0}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607383c1-e9a3-4c83-a610-635372befdca",
   "metadata": {},
   "source": [
    "Poniżej przykład z przekazaniem wielu argumentów do funkcji uruchamianej w ramach procesu poprzez wykorzystanie metody `Pool.starmap`.\n",
    "\n",
    "_**Przykład 4**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a161bea-dc70-4bb3-9f48-c33d20eb49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik: process_pool_3.py\n",
    "\n",
    "import multiprocessing as mp\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "def open_file(filepath, sep=','):\n",
    "    return f'Otwieram {filepath} używając separatora {sep}'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print('Uruchamianie procesów...')\n",
    "    t0 = perf_counter()\n",
    "    params = [\n",
    "        ('data.csv', ),\n",
    "        ('names.csv', ';'),\n",
    "        ('products.csv', ),\n",
    "        ('other.csv', '^'),\n",
    "        ('costam.csv', ',')]\n",
    "\n",
    "    # tworzymy pulę 4 procesów\n",
    "    with mp.Pool(processes=4) as pool:\n",
    "        # wyniki są zbierane do listy\n",
    "        results = pool.starmap(open_file, params)\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"open_file{params[i]} = {result}\")\n",
    "\n",
    "    print(f'Czas wykonania: {perf_counter() - t0}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc36ad6-9249-4a7d-be90-b9a30c9d9ed0",
   "metadata": {},
   "source": [
    "**Przekazywanie informacji między procesami przez obiekt `multiprocessing.Queue`**\n",
    "\n",
    "_**Przykład 5**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018779f-71bf-4a74-8c54-7169651348b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik: queue_1.py\n",
    "\n",
    "from multiprocessing import Process, Queue, Pool\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "def f(q):\n",
    "    q.put(time.time())\n",
    "    print(f'Aktualny rozmiar kolejki: {q.qsize()}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "\n",
    "    print(f'Zostanie uruchomionych {os.cpu_count()} procesów.')\n",
    "    for _ in range(os.cpu_count()):\n",
    "        Process(target=f, args=(q,)).start()\n",
    "\n",
    "    while not q.empty():\n",
    "        print(q.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8297f6-957e-4f67-b890-19b7bded46ee",
   "metadata": {},
   "source": [
    "Wynik tego przykładu może być za każdym razem inny. Dlaczego? Procesy jak wiemy uruchamiane są poza głównym procesem, który przy tym zapisie nie jest blokowany i kod wyświetlający zawartość kolejki wykona się tuż po utworzeniu wszystkich procesów, bez oczekiwania na ich zakończenie.\n",
    "\n",
    "W poniższym przykładzie czekamy, aż wszystkie procesy się zakończą i dopiero kontynuujemy wykoanie procesu nadrzędnego.\n",
    "\n",
    "_**Przykład 6**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049fc40-2717-49cd-b79c-1236b1f8aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik: queue_2.py\n",
    "from multiprocessing import Process, Queue, Pool\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "def f(q):\n",
    "    q.put(time.time())\n",
    "    print(f'Aktualny rozmiar kolejki: {q.qsize()}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    procesess = []\n",
    "\n",
    "    print(f'Zostanie uruchomionych {os.cpu_count()} procesów.')\n",
    "    for _ in range(os.cpu_count()):\n",
    "        procesess.append(Process(target=f, args=(q,)))\n",
    "\n",
    "    for p in procesess:\n",
    "        p.start()      \n",
    "    # czekamy, aż wszystkie procesy zakończą pracę\n",
    "    for p in procesess:\n",
    "        p.join()\n",
    "\n",
    "    while not q.empty():\n",
    "        print(q.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db387278-57f0-4002-a6e8-fa879526eed2",
   "metadata": {},
   "source": [
    "Przykład wykorzystania obiektu `multiprocessing.Pipe` został skopiowany z oficjalnej dokumentacji (https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes). Potok jest otwierany zawsze w dwóch kierunkach (duplex). Komunikacja obywa się poprzez wywołanie metody `send` oraz `recv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d06df-788a-46f0-a1da-b2b1a3cc6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96a30f-0166-4300-b31d-341e02485cc4",
   "metadata": {},
   "source": [
    "Przedstawione powyżej przykłady to zaledwie wycinek możliwości pakietu `multiprocessing`, który oferuje jeszcze niskopoziomowe możliwości synchronizacji procesów (blokady, bariery "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fe7a6-3354-48df-92a3-303e545db154",
   "metadata": {},
   "source": [
    "## 2. Moduł `concurrent.futures`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c649e-daaf-42d3-a7c7-531c5ac8581d",
   "metadata": {},
   "source": [
    "Ten moduł dostarcza wysokopoziomowych metod na asynchroniczne uruchamianie wątków lub procesów za pośrednictwem interfejsu znajdującego się w abstrakcyjnej klasie `Executor`. Są to odpowiednio `ThreadPoolExecutor` oraz `ProcessPoolExecutor`\n",
    "\n",
    "\n",
    "The concurrent.futures module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with threads, using ThreadPoolExecutor, or separate processes, using ProcessPoolExecutor. Both implement the same interface, which is defined by the abstract Executor class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adbd90e-6cb7-4a75-a19d-30c2e67be307",
   "metadata": {},
   "source": [
    "W poniższym przykładzie czas wykonania będzie zbliżony do przykładu 3, jednak bez blokowania co powoduje, że wyniki nie zostaną wyświetlone na raz, ale będą pojawiały się stopniowo w kolejności ich wykonania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd7799-60f0-4588-a216-cff09a2f23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plik futures_poolexecutor_1.py\n",
    "# źródło: https://realpython.com/python-parallel-processing/\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def fib(n):\n",
    "    return n if n < 2 else fib(n - 2) + fib(n - 1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        results = executor.map(fib, range(40))\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"fib({i}) = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6098cb54-638a-4430-8177-96a9cdd66a6b",
   "metadata": {},
   "source": [
    "## Zadania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44f326-95d6-482a-88dd-cd07be420572",
   "metadata": {},
   "source": [
    "Na potrzeby zadania 3 przygotowano kod, który pozwala stworzyć fikcyjny zbiór danych o określonej liczbie obserwacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67817d5e-9765-49ff-a60b-d28f34fc59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deklaracja zbiorów wartości dla poszczególnych kolumn przyszłego zbioru danych\n",
    "header = ['id', 'firstname', 'lastname', 'age', 'salary']\n",
    "firstnames = ['Adam', 'Katarzyna', 'Krzysztof', 'Marek', 'Aleksandra', 'Zbigniew', 'Wojciech', 'Mieczysław', 'Agata', 'Wisława']\n",
    "lastnames = ['Mieczykowski', 'Kowalski', 'Malinowski' , 'Szczaw', 'Glut', 'Barański', 'Brzęczyszczykiewicz', 'Wróblewski', 'Wlotka', 'Pysla']\n",
    "age = {'min': 18, 'max': 68}\n",
    "salary = {'min': 3200, 'max': 12500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cee517-1d3c-4374-8f31-d327ef2d2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7e8cc-aa0f-4827-a079-9d2dd48b9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja do generowania fikcyjnego datasetu\n",
    "# n_rows oznacza ilość wierszy, którą chcemy finalnie uzyskać\n",
    "\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_dataset(filename, n_rows=100, chunk_size=100000):\n",
    "    rows = []\n",
    "    rows.append(header)\n",
    "    mu = (salary['max'] + salary['min']) / 2\n",
    "    sigma = 1000\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as filehandler:\n",
    "        \n",
    "        for id in tqdm(range(1, n_rows + 1), total=n_rows, desc=\"Building dataset...\"):\n",
    "            row = [\n",
    "                f'{id}', \n",
    "                f'{random.choice(firstnames)}', \n",
    "                f'{random.choice(lastnames)}', \n",
    "                f\"{random.randint(age['min'], age['max'])}\",\n",
    "                f\"{round(float(random.normalvariate(mu=mu, sigma=sigma)), 2)}\"\n",
    "            ]\n",
    "            rows.append(row)\n",
    "            if id % chunk_size == 0:\n",
    "                filehandler.writelines([f\"{','.join(row)}\\n\" for row in rows])\n",
    "                rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efb41d-5d2f-42c1-92c3-9b214383c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# około 750MB zostanie zapisanych w pliku csv, dostosuj ilość rekordów do swoich potrzeb\n",
    "build_dataset('employee.csv', 20_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97261545-3b01-414d-a56a-e222f806cdce",
   "metadata": {},
   "source": [
    "**Zadanie 2**  \n",
    "\n",
    "Przepisz kod zadania 3 z lab 11 tak, aby wykorzystywał tym razem klasę `ThreadPoolExecutor` wykorzystującą maksymalnie połowę dostępnych rdzeni komputera, na którym jest uruchamiany.\n",
    "\n",
    "**Zadanie 3**\n",
    "\n",
    "Korzystając z kodu do generowania fikcyjnego zbioru danych wygeneruj 4 zbiory o rozmiarze 10 milionów rekordów każdy i zapisz do plików. Następnie załaduj te zbiory sekwencyjnie do ramek danych pandas i scal je w jedną ramkę mierząc czas tej operacji (wczytanie + scalenie).\n",
    "\n",
    "Napisz kod, który wykorzystując `ProcessPoolExecutor` będzie wczytywał kolejne pliki utworzone wcześniej w oddzielnych procesach do ramek pandas, a następnie scal te ramki w jedną. Również zmierz czas tej operacji.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
